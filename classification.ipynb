{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6283db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19fb467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d22285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_keras.layers import Input,Dense\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,Conv2DTranspose\n",
    "from tf_keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from tf_keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
    "import tf_keras.backend as K\n",
    "from tf_keras.preprocessing.image import ImageDataGenerator\n",
    "from tf_keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (256,256)\n",
    "\n",
    "train_dir = 'dataset/TBX11K/imgs/train/'\n",
    "test_dir = 'dataset/TBX11K/imgs/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import define_data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "train = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_y = define_data(train_dir,IMG_SIZE)\n",
    "target_val = train.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be448d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(train_data, ),target_val,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0032f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_keras\n",
    "from tf_keras.applications.mobilenet import MobileNet,preprocess_inputs\n",
    "from tf_keras.applications.mobilenet_v2 import MobileNetV2,preprocess_inputs\n",
    "from tf_keras.applications.resnet import ResNet50,preprocess_inputs\n",
    "from tf_keras.applications.resnet import ResNet101\n",
    "from tf_keras.applications.resnet import ResNet152\n",
    "from tf_keras.applications.vgg19 import VGG19,preprocess_inputs\n",
    "from tf_keras.applications.vgg16 import VGG16,preprocess_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class backboneModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "\n",
    "    def add_model(self,name,fn,args,head_fn):\n",
    "        self.models[name] = {\n",
    "            \"fn\":fn,\n",
    "            \"args\":args,\n",
    "            \"head\":head_fn\n",
    "        }\n",
    "    \n",
    "    def build(self,name,input_shape,new_args=None):\n",
    "        model = self.models[name]\n",
    "        args = model[\"args\"].copy()\n",
    "        if new_args:\n",
    "            args = new_args\n",
    "        base_model = model[\"fn\"](\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=INPUT_SHAPE,\n",
    "            **args\n",
    "        )\n",
    "        full_model = model[\"head\"](input_shape,base_model)\n",
    "        return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_net = MobileNetV2\n",
    "preprocess = tf_keras.applications.mobilenetv2.preprocess_inputs\n",
    "args = {\n",
    "    \"input_tensor\": inputs,\n",
    "    \"weights\": \"imagenet\",\n",
    "    \"include_top\": False,\n",
    "    \"alpha\": 0.35\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_args = {ResNet50.__name__:{\n",
    "                \"weights\"=\"imagenet\",\n",
    "                \"include_top\"=False,\n",
    "                \"input_shape\"=INPUT_SHAPE},\n",
    "            ResNet101.__name__:{\n",
    "                \"weights\"=\"imagenet\",\n",
    "                \"include_top\"=False,\n",
    "                \"input_shape\"=INPUT_SHAPE},\n",
    "            ResNet152.__name__:{\n",
    "                \"weights\"=\"imagenet\",\n",
    "                \"include_top\"=False,\n",
    "                \"input_shape\"=INPUT_SHAPE},\n",
    "            \"resnet18\":{\n",
    "                \"weights\"=\"imagenet\",\n",
    "                \"include_top\"=False,\n",
    "                \"input_shape\"=INPUT_SHAPE},\n",
    "            MobileNet.__name__:{\n",
    "                \"input_tensor\": INPUT_SHAPE,\n",
    "                \"weights\": \"imagenet\",\n",
    "                \"include_top\": False,\n",
    "                \"alpha\": 0.35\n",
    "            },\n",
    "            MobileNetV2.__name__:{\n",
    "                \"input_tensor\": INPUT_SHAPE,\n",
    "                \"weights\": \"imagenet\",\n",
    "                \"include_top\": False,\n",
    "                \"alpha\": 0.35\n",
    "                }\n",
    "            }\n",
    "custom_heads = {\n",
    "    ResNet50.__name__:resnet_model_head,\n",
    "    ResNet101.__name__:resnet_model_head,\n",
    "    ResNet152.__name__:resnet_model_head,\n",
    "    \"resnet18\":resnet_model_head,\n",
    "    MobileNet.__name__:mobilenet_model_head,\n",
    "    MobileNetV2.__name__:mobilenet_model_head\n",
    "}\n",
    "model_farm = backboneModel()\n",
    "model_farm.add_model(back_net.__name__,back_net,std_args[back_net.__name__],custom_heads[back_net.__name__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_model_head(input_shape,base_model):\n",
    "    inputs = Input(shape=input_shape,name=\"input_image\")\n",
    "    x=base_model.get_layer('out_relu').output\n",
    "    x=GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    output=Dense(3,activation=\"softmax\")(x)\n",
    "    return tf_keras.Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape=(256,256,3))\n",
    "model.compile(optimizer=tf_keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            # loss=keras.losses.BinaryCrossentropy(),\n",
    "            # metrics = [keras.metrics.AUC(from_logits=True)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filepath=f'{back_net.__name__}/class_weights.{{epoch:02d}}-{{val_loss:.2f}}.weights.h5'\n",
    "callback = [\n",
    "    tf_keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.1, patience=3, verbose=1, min_lr=1e-8 ),\n",
    "    tf_keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    tf_keras.callbacks.ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        save_best_only=True,save_weights_only=True,verbose=1)\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "history = model.fit(x=x_train, \n",
    "                    y = y_train,\n",
    "                    validation_split=0.15,\n",
    "                    epochs=15,\n",
    "                    batch_size = 16,\n",
    "                   callbacks=callback)\n",
    "\n",
    "elapsed_time = datetime.datetime.now() - start_time\n",
    "print('Cell ran in ' + str(elapsed_time.seconds) + ' seconds and ' + str(elapsed_time.microseconds) + ' microseconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['train acc','validation acc'])\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history[ 'val_loss'])\n",
    "plt.legend(['train loss','validation loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef190787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_keras\n",
    "\n",
    "\n",
    "def model(input_shape):\n",
    "    inputs = Input(shape=input_shape,name=\"input_image\")\n",
    "    base_model = back_net(input_tensor = inputs, weights=\"imagenet\", include_top=False, alpha=0.35)\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    output=Dense(3,activation=\"softmax\")(x)\n",
    "    return tf_keras.Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f45f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape=(256,256,3))\n",
    "model.load_weights('MobileNetV2\\class_weights.09-0.30.weights.h5')\n",
    "model.compile(optimizer=tf_keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf_keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf_keras.metrics.Accuracy()])\n",
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74881cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((y_test.shape[0]))\n",
    "for i,p in enumerate(predictions):\n",
    "    l = np.argmax(p)\n",
    "    preds[i] = l\n",
    "\n",
    "y = [np.argmax(yy) for yy in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1addfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573db3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y,preds,labels=[0,1,2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"NORM\",\"NON-TB\",\"TB\"])\n",
    "disp.plot()\n",
    "plt.savefig(f\"{back_net.__name__}-confusionmatrix.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
